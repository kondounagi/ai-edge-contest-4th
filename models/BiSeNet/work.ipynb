{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run  tools/my_train.py  --finetune-from ./model_final.pth --model bisenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-4843734ef9c2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4843734ef9c2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    python -m torch.distributed.launch --nproc_per_node=2 tools/train.py  --model bisenetv2\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#configを,cityscapes用に書き換えると，以下のコード(最初から学習)は実行できる．\n",
    "python -m torch.distributed.launch --nproc_per_node=2 tools/train.py  --model bisenetv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "signateを読み込むようにconfigを書き換えるとエラー．\n",
    "- dataloaderを作る部分を書き換える  \n",
    "\n",
    "finetuneするようにパスを追加すると，dataloaderの読み込みで止まる．\n",
    "\n",
    "↑train.pyのmodelを読み込むとこを書き換えることで解決\n",
    "dataloaderが上手くgpuにのってなかった？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m torch.distributed.launch --nproc_per_node=2 tools/train.py --finetune-from ./model_final.pth --model bisenetv2 # or bisenetv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./train.txt\"\n",
    "with open(path, mode='w') as f:\n",
    "    for i in range(0,2243):\n",
    "        f.write(\"seg_train_images/train_{}.jpg,seg_train_annotations/train_{}.png\\n\".format(str(i).zfill(4), str(i).zfill(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv2.imread(\"./datasets/signate/seg_train_annotations/train_0000.png\",0)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0 255]\n",
      " [193 214   0]\n",
      " [180   0 129]\n",
      " [255 121 166]\n",
      " [255   0   0]\n",
      " [ 65 166   1]\n",
      " [208 149   1]\n",
      " [255 255   0]\n",
      " [255 134   0]\n",
      " [  0 152 225]\n",
      " [  0 203 151]\n",
      " [ 85 255  50]\n",
      " [ 92 136 125]\n",
      " [ 69  47 142]\n",
      " [136  45  66]\n",
      " [  0 255 255]\n",
      " [215   0 255]\n",
      " [180 131 135]\n",
      " [ 82  99   0]\n",
      " [ 86  62  67]]\n",
      "[[13 13 13 ...  9  9  9]\n",
      " [13 13 13 ...  9  9  9]\n",
      " [13 13 13 ...  9  9  9]\n",
      " ...\n",
      " [13 13 13 ... 13 13 13]\n",
      " [13 13 13 ... 13 13 13]\n",
      " [13 13 13 ... 13 13 13]]\n"
     ]
    }
   ],
   "source": [
    "%run tools/demo_signate.py --model bisenetv2 --weight-path ./res/model_2020_09_09_20_24.pth --img-path ./train_0000.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_info_signate = [\n",
    "    {\"hasInstances\": False, \"category\": \"void\", \"catid\": 0, \"name\": \"unlabeled\", \"ignoreInEval\": True, \"id\": 0, \"color\": [0, 0, 0], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"void\", \"catid\": 0, \"name\": \"ego vehicle\", \"ignoreInEval\": True, \"id\": 1, \"color\": [0, 0, 0], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"void\", \"catid\": 0, \"name\": \"rectification border\", \"ignoreInEval\": True, \"id\": 2, \"color\": [0, 0, 0], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"void\", \"catid\": 0, \"name\": \"out of roi\", \"ignoreInEval\": True, \"id\": 3, \"color\": [0, 0, 0], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"void\", \"catid\": 0, \"name\": \"static\", \"ignoreInEval\": True, \"id\": 4, \"color\": [0, 0, 0], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"void\", \"catid\": 0, \"name\": \"dynamic\", \"ignoreInEval\": True, \"id\": 5, \"color\": [111, 74, 0], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"void\", \"catid\": 0, \"name\": \"ground\", \"ignoreInEval\": True, \"id\": 6, \"color\": [81, 0, 81], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"flat\", \"catid\": 1, \"name\": \"road\", \"ignoreInEval\": False, \"id\": 7, \"color\": [69, 47, 142], \"trainId\": 0},\n",
    "    {\"hasInstances\": False, \"category\": \"flat\", \"catid\": 1, \"name\": \"sidewalk\", \"ignoreInEval\": False, \"id\": 8, \"color\": [0, 255, 255], \"trainId\": 1},\n",
    "    {\"hasInstances\": False, \"category\": \"flat\", \"catid\": 1, \"name\": \"parking\", \"ignoreInEval\": True, \"id\": 9, \"color\": [69, 47, 142], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"flat\", \"catid\": 1, \"name\": \"rail track\", \"ignoreInEval\": True, \"id\": 10, \"color\": [230, 150, 140], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"construction\", \"catid\": 2, \"name\": \"building\", \"ignoreInEval\": False, \"id\": 11, \"color\": [0, 203, 151], \"trainId\": 2},\n",
    "    {\"hasInstances\": False, \"category\": \"construction\", \"catid\": 2, \"name\": \"wall\", \"ignoreInEval\": False, \"id\": 12, \"color\": [92, 136, 125], \"trainId\": 3},\n",
    "    {\"hasInstances\": False, \"category\": \"construction\", \"catid\": 2, \"name\": \"fence\", \"ignoreInEval\": False, \"id\": 13, \"color\": [92, 136, 125], \"trainId\": 4},\n",
    "    {\"hasInstances\": False, \"category\": \"construction\", \"catid\": 2, \"name\": \"guard rail\", \"ignoreInEval\": True, \"id\": 14, \"color\": [92, 136, 125], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"construction\", \"catid\": 2, \"name\": \"bridge\", \"ignoreInEval\": True, \"id\": 15, \"color\": [0, 203, 151], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"construction\", \"catid\": 2, \"name\": \"tunnel\", \"ignoreInEval\": True, \"id\": 16, \"color\": [0, 203, 151], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"object\", \"catid\": 3, \"name\": \"pole\", \"ignoreInEval\": False, \"id\": 17, \"color\": [180, 131, 135], \"trainId\": 5},\n",
    "    {\"hasInstances\": False, \"category\": \"object\", \"catid\": 3, \"name\": \"polegroup\", \"ignoreInEval\": True, \"id\": 18, \"color\": [180, 131, 135], \"trainId\": 255},\n",
    "    {\"hasInstances\": False, \"category\": \"object\", \"catid\": 3, \"name\": \"traffic light\", \"ignoreInEval\": False, \"id\": 19, \"color\": [255, 255, 0], \"trainId\": 6},\n",
    "    {\"hasInstances\": False, \"category\": \"object\", \"catid\": 3, \"name\": \"traffic sign\", \"ignoreInEval\": False, \"id\": 20, \"color\": [255, 134, 0], \"trainId\": 7},\n",
    "    {\"hasInstances\": False, \"category\": \"nature\", \"catid\": 4, \"name\": \"vegetation\", \"ignoreInEval\": False, \"id\": 21, \"color\": [85, 255, 50], \"trainId\": 8},\n",
    "    {\"hasInstances\": False, \"category\": \"nature\", \"catid\": 4, \"name\": \"terrain\", \"ignoreInEval\": False, \"id\": 22, \"color\": [85, 255, 50], \"trainId\": 9},\n",
    "    {\"hasInstances\": False, \"category\": \"sky\", \"catid\": 5, \"name\": \"sky\", \"ignoreInEval\": False, \"id\": 23, \"color\": [0, 152, 225], \"trainId\": 10},\n",
    "    {\"hasInstances\": True, \"category\": \"human\", \"catid\": 6, \"name\": \"person\", \"ignoreInEval\": False, \"id\": 24, \"color\": [255, 0, 0], \"trainId\": 11},\n",
    "    {\"hasInstances\": True, \"category\": \"human\", \"catid\": 6, \"name\": \"rider\", \"ignoreInEval\": False, \"id\": 25, \"color\": [208, 149, 1], \"trainId\": 12},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"car\", \"ignoreInEval\": False, \"id\": 26, \"color\": [0, 0, 255], \"trainId\": 13},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"truck\", \"ignoreInEval\": False, \"id\": 27, \"color\": [180, 0, 129], \"trainId\": 14},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"bus\", \"ignoreInEval\": False, \"id\": 28, \"color\": [193, 214, 0], \"trainId\": 15},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"caravan\", \"ignoreInEval\": True, \"id\": 29, \"color\": [255, 121, 166], \"trainId\": 255},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"trailer\", \"ignoreInEval\": True, \"id\": 30, \"color\": [255, 121, 166], \"trainId\": 255},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"train\", \"ignoreInEval\": False, \"id\": 31, \"color\": [255, 121, 166], \"trainId\": 16},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"motorcycle\", \"ignoreInEval\": False, \"id\": 32, \"color\": [65, 166, 1], \"trainId\": 17},\n",
    "    {\"hasInstances\": True, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"bicycle\", \"ignoreInEval\": False, \"id\": 33, \"color\": [208, 149, 1], \"trainId\": 18},\n",
    "    {\"hasInstances\": False, \"category\": \"vehicle\", \"catid\": 7, \"name\": \"license plate\", \"ignoreInEval\": True, \"id\": -1, \"color\": [0, 0, 142], \"trainId\": -1}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_info_signate[0][\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_info_signate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-29a722773d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_info_signate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_info_signate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_info_signate' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import  cv2\n",
    "palette = []\n",
    "for i in range(len(labels_info_signate)):\n",
    "    palette.append(labels_info_signate[i][\"color\"])\n",
    "\n",
    "palette = np.array(palette, dtype=np.uint8)\n",
    "palette = palette.reshape(-1,5,3)\n",
    "palette_gray = cv2.cvtColor(palette, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "print(palette_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1e87d779daf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./train_0000.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"res.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mIOU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/ai-edge-contest-4th/models/BiSeNet/tools/seg_codes/IOU.py\u001b[0m in \u001b[0;36mIOU\u001b[0;34m(true, pred)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0miou_over_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimages_intersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_intersection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_intersection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0miou_per_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from tools.seg_codes.IOU import IOU\n",
    "true = cv2.imread(\"./train_0000.png\")\n",
    "pred = cv2.imread(\"res.png\")\n",
    "IOU(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29 183  69 166  76 117 150 226 155 115 136 181 122  64  75 179  93 146\n",
      "  82  70]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "palette = [[0, 0, 255],\n",
    "           [193, 214, 0],\n",
    "           [180, 0, 129],\n",
    "           [255, 121, 166],\n",
    "           [255, 0, 0],\n",
    "           [65, 166, 1],\n",
    "           [208, 149, 1],\n",
    "           [255, 255, 0],\n",
    "           [255, 134, 0],\n",
    "           [0, 152, 225],\n",
    "           [0, 203, 151],\n",
    "           [85, 255, 50],\n",
    "           [92, 136, 125],\n",
    "           [69, 47, 142],\n",
    "           [136, 45, 66],\n",
    "           [0, 255, 255],\n",
    "           [215, 0, 255],\n",
    "           [180, 131, 135],\n",
    "           [81, 99, 0],\n",
    "           [86, 62, 67]]\n",
    "'''\n",
    "label_name = [Car,\n",
    "    Bus,\n",
    "    Truck,\n",
    "    SVehicle,\n",
    "    Pedestrian,\n",
    "    Motorbike,\n",
    "    Bicycle,\n",
    "    Signal,\n",
    "    Signs,\n",
    "    Sky,\n",
    "    Building,\n",
    "    Natural,\n",
    "    Wall,\n",
    "    Lane,\n",
    "    Ground,\n",
    "    Sidewalk,\n",
    "    RoadShoulder,\n",
    "    Obstacle, \n",
    "    others,\n",
    "    own]\n",
    "'''\n",
    "palette = np.array(palette, dtype=np.uint8)\n",
    "palette = palette.reshape(-1,5,3)\n",
    "palette_gray = cv2.cvtColor(palette, cv2.COLOR_RGB2GRAY)\n",
    "palette_gray = palette_gray.reshape(-1)\n",
    "print(palette_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "city2sig_pallette = np.array([0, 70, 0, 0, 0,\n",
    "                              0, 0, 64, 179, 0,\n",
    "                              0, 136, 122, 122, 0,\n",
    "                              0, 0, 146, 0, 226,\n",
    "                              155, 181, 75, 115, 76,\n",
    "                              117, 29, 69, 183, 0,\n",
    "                              0, 82, 117, 150, 0, 0])\n",
    "sig_pallette = np.array([ 29, 183,  69, 166,\n",
    " 76, 117, 150, 226,\n",
    " 155, 115, 136, 181,\n",
    " 122,  64,  75, 179,\n",
    "93, 146,  82,  70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26], [28], [27], [], [24], [25, 32], [33], [19], [20], [23], [11], [21], [12, 13], [7], [22], [8], [], [17], [31], [1]]\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "for i in range(len(sig_pallette)):\n",
    "    a = []\n",
    "    for j in range(len(city2sig_pallette)):\n",
    "        if sig_pallette[i] == city2sig_pallette[j]:\n",
    "               a.append(j)\n",
    "    ans.append(a) \n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136 136 136 ... 114 114 114]\n",
      " [136 136 136 ... 114 114 114]\n",
      " [136 136 136 ... 114 114 114]\n",
      " ...\n",
      " [ 69  69  69 ...  69  69  69]\n",
      " [ 69  69  69 ...  69  69  69]\n",
      " [ 69  69  69 ...  69  69  69]]\n",
      "[[136 136 136 ... 115 115 115]\n",
      " [136 136 136 ... 115 115 115]\n",
      " [136 136 136 ... 115 115 115]\n",
      " ...\n",
      " [ 70  70  70 ...  70  70  70]\n",
      " [ 70  70  70 ...  70  70  70]\n",
      " [ 70  70  70 ...  70  70  70]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps, ImageFilter \n",
    "img = cv2.imread(\"./datasets/signate_dataset/seg_train_annotations/train_0000.png\", 0)\n",
    "print(img)\n",
    "mask = Image.open(\"./datasets/signate_dataset/seg_train_annotations/train_0000.png\").convert('L')\n",
    "mask = np.asarray(mask)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,  13,\n",
       "       255, 255, 255, 255,   2,  19, 255, 255, 255, 255,  14,   4, 255,\n",
       "       255, 255, 255, 255,  18, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255,  16, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   9, 255,\n",
       "         5, 255, 255, 255, 255,  12, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255,  10, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255,  17, 255, 255, 255,   6, 255, 255, 255, 255,   8,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   3, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255,  15, 255,  11,\n",
       "       255,   1, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255,   7, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = np.full(255,255)\n",
    "signate_pallette = [29, 183, 69, 166, 76,\n",
    "                    117, 150, 226, 155, 115,\n",
    "                    136, 181, 122,  64,  75,\n",
    "                    179,  93, 146,  82,  70]\n",
    "for i in range(len(ans)):\n",
    "    for j in range(len(signate_pallette)):\n",
    "        if i == signate_pallette[j]:\n",
    "            ans[i] = j\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self.head = SegmentHead(128, 1024, n_classes)  \n",
    "だけを初期化し，finetuneしてみる(初期化せずにやるより良さそう)  \n",
    "15iter mIOU about 0.02  \n",
    "150iter about mIOU 0.18    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#実行コードは以下(gpu2枚の場合)\n",
    "#ターミナルで実行する\n",
    "#python -m torch.distributed.launch --nproc_per_node=2 tools/train_from_signate.py --finetune-from ./model_final.pth --model bisenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
